"apiVersion": |-
  argoproj.io/v1alpha1
"kind": |-
  Workflow
"metadata":
  "annotations":
    "pipelines.kubeflow.org/pipeline_spec": |-
      {"description": "The pipeline training and deploying the Covertype classifierpipeline_yaml", "inputs": [{"default": "mlops-workshop", "name": "project_id"}, {"default": "\nSELECT *\nFROM \n  `mlops-workshop.lab_12.covertype` AS cover\nWHERE \n  MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(cover))), 10) in (8)", "name": "query"}, {"default": "training_split", "name": "table_id"}, {"default": "lab_12", "name": "dataset_id"}, {"default": "US", "name": "dataset_location"}, {"default": "gs://mlops-workshop-lab-12/sample_data", "name": "output_gcs_path"}], "name": "Covertype Classifier Training"}
  "generateName": |-
    covertype-classifier-training-
"spec":
  "arguments":
    "parameters":
    - "name": |-
        project_id
      "value": |-
        mlops-workshop
    - "name": |-
        query
      "value": "\nSELECT *\nFROM \n  `mlops-workshop.lab_12.covertype` AS cover\n\
        WHERE \n  MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(cover))), 10) in (8)"
    - "name": |-
        table_id
      "value": |-
        training_split
    - "name": |-
        dataset_id
      "value": |-
        lab_12
    - "name": |-
        dataset_location
      "value": |-
        US
    - "name": |-
        output_gcs_path
      "value": |-
        gs://mlops-workshop-lab-12/sample_data
  "entrypoint": |-
    covertype-classifier-training
  "serviceAccountName": |-
    pipeline-runner
  "templates":
  - "container":
      "args":
      - |-
        kfp_component.google.bigquery
      - |-
        query
      - |-
        --query
      - |-
        {{inputs.parameters.query}}
      - |-
        --project_id
      - |-
        {{inputs.parameters.project_id}}
      - |-
        --dataset_id
      - |-
        {{inputs.parameters.dataset_id}}
      - |-
        --table_id
      - |-
        {{inputs.parameters.table_id}}
      - |-
        --dataset_location
      - |-
        {{inputs.parameters.dataset_location}}
      - |-
        --output_gcs_path
      - |-
        {{inputs.parameters.output_gcs_path}}
      - |-
        --job_config
      - ""
      "command": []
      "env":
      - "name": |-
          KFP_POD_NAME
        "value": |-
          {{pod.name}}
      - "name": |-
          KFP_POD_NAME
        "valueFrom":
          "fieldRef":
            "fieldPath": |-
              metadata.name
      - "name": |-
          KFP_NAMESPACE
        "valueFrom":
          "fieldRef":
            "fieldPath": |-
              metadata.namespace
      - "name": |-
          GOOGLE_APPLICATION_CREDENTIALS
        "value": |-
          /secret/gcp-credentials/user-gcp-sa.json
      - "name": |-
          CLOUDSDK_AUTH_CREDENTIAL_FILE_OVERRIDE
        "value": |-
          /secret/gcp-credentials/user-gcp-sa.json
      "image": |-
        gcr.io/ml-pipeline/ml-pipeline-gcp:9ad7d7dd9776ce75a83712f5723db2ef93ba5c26
      "volumeMounts":
      - "mountPath": |-
          /secret/gcp-credentials
        "name": |-
          gcp-credentials-user-gcp-sa
    "inputs":
      "parameters":
      - "name": |-
          dataset_id
      - "name": |-
          dataset_location
      - "name": |-
          output_gcs_path
      - "name": |-
          project_id
      - "name": |-
          query
      - "name": |-
          table_id
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"description": "A Kubeflow Pipeline component to submit a query to Google Cloud Bigquery \nservice and dump outputs to a Google Cloud Storage blob. \n", "inputs": [{"description": "The query used by Bigquery service to fetch the results.", "name": "query", "type": "String"}, {"description": "The project to execute the query job.", "name": "project_id", "type": "GCPProjectID"}, {"default": "", "description": "The ID of the persistent dataset to keep the results of the query.", "name": "dataset_id", "type": "String"}, {"default": "", "description": "The ID of the table to keep the results of the query. If absent, the operation will generate a random id for the table.", "name": "table_id", "type": "String"}, {"default": "", "description": "The path to the Cloud Storage bucket to store the query output.", "name": "output_gcs_path", "type": "GCSPath"}, {"default": "US", "description": "The location to create the dataset. Defaults to `US`.", "name": "dataset_location", "type": "String"}, {"default": "", "description": "The full config spec for the query job.See  [QueryJobConfig](https://googleapis.github.io/google-cloud-python/latest/bigquery/generated/google.cloud.bigquery.job.QueryJobConfig.html#google.cloud.bigquery.job.QueryJobConfig)  for details.", "name": "job_config", "type": "Dict"}], "metadata": {"labels": {"add-pod-env": "true"}}, "name": "Bigquery - Query", "outputs": [{"description": "The path to the Cloud Storage bucket containing the query output in CSV format.", "name": "output_gcs_path", "type": "GCSPath"}, {"name": "MLPipeline UI metadata", "type": "UI metadata"}]}
      "labels":
        "add-pod-env": |-
          true
    "name": |-
      bigquery-query
    "outputs":
      "artifacts":
      - "name": |-
          mlpipeline-ui-metadata
        "path": |-
          /mlpipeline-ui-metadata.json
      - "name": |-
          bigquery-query-output_gcs_path
        "path": |-
          /tmp/kfp/output/bigquery/query-output-path.txt
    "volumes":
    - "name": |-
        gcp-credentials-user-gcp-sa
      "secret":
        "secretName": |-
          user-gcp-sa
  - "dag":
      "tasks":
      - "arguments":
          "parameters":
          - "name": |-
              dataset_id
            "value": |-
              {{inputs.parameters.dataset_id}}
          - "name": |-
              dataset_location
            "value": |-
              {{inputs.parameters.dataset_location}}
          - "name": |-
              output_gcs_path
            "value": |-
              {{inputs.parameters.output_gcs_path}}
          - "name": |-
              project_id
            "value": |-
              {{inputs.parameters.project_id}}
          - "name": |-
              query
            "value": |-
              {{inputs.parameters.query}}
          - "name": |-
              table_id
            "value": |-
              {{inputs.parameters.table_id}}
        "name": |-
          bigquery-query
        "template": |-
          bigquery-query
    "inputs":
      "parameters":
      - "name": |-
          dataset_id
      - "name": |-
          dataset_location
      - "name": |-
          output_gcs_path
      - "name": |-
          project_id
      - "name": |-
          query
      - "name": |-
          table_id
    "name": |-
      covertype-classifier-training

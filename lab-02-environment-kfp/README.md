# Setting up an MLOps environment on GCP.

The labs in this repo are designed to run in a reference MLOps environment. The environment is configured to support effective development and operationalization of production grade ML workflows.

![Reference topolgy](/images/lab_300.png)

The core services in the environment are:
- AI Platform Notebooks - ML experimentation and development
- AI Platform Training - scalable, serverless model training
- AI Platform Prediction - scalable, serverless model serving
- Dataflow - distributed data processing
- BigQuery - analytics data warehouse
- Cloud Storage - unified object storage
- TensorFlow Extended/Kubeflow Pipelines (TFX/KFP) - machine learning pipelines
- Cloud SQL - machine learning metadata  management
- Cloud Build - CI/CD
    

In this lab, you will provision a lightweight deployment of **Kubeflow Pipelines**. 

Since other services are configured in the `lab-01-environment-notebook` lab you need to complete that lab before proceeding.



## Deploying Kubeflow Pipelines 

The below diagrame shows an MVP environment for a lightweight deployment of Kubeflow Pipelines on GCP:

![KFP Deployment](/images/kfp.png)

The environment includes:
- A VPC to host GKE cluster
- A GKE cluster to host KFP services
- A Cloud SQL managed MySQL instance to host KFP and ML Metadata databases
- A Cloud Storage bucket to host artifact repository

The KFP services are deployed to the GKE cluster and configured to use the Cloud SQL managed MySQL instance. The KFP services access the Cloud SQL through [Cloud SQL Proxy](https://cloud.google.com/sql/docs/mysql/sql-proxy). External clients use [Inverting Proxy](https://github.com/google/inverting-proxy) to interact with the KFP services.

The provisioning of the infrastructure components and installation of Kubeflow Pipelines has been automated with Terraform and Kustomize. The Terraform HCL configurations can be found in the `kfp/terraform` folder. The Kustomize overlays are in the `kfp/kustomize` folder.

*The current versions of the labs have been tested with Kubeflow Pipelines v1.36. KFP v1.37, v1.38, v1.39 introduced [the issue](https://github.com/kubeflow/pipelines/issues/2764) that causes some labs to fail. After the issue is addressed we will update the setup to utilize the newer version of KFP.*

### Deploying infrastructure services to host Kubeflow Pipelines

1. Open **Cloud Shell**

3. Provision infrastructure. From the `Lab-00-EnvironmentSetup/kfp` folder execute:
```
./provision-infra [PROJECT_ID] [REGION] [ZONE] [PREFIX]
```
Where 
- `[PROJECT_ID]` - your project ID
- `[REGION]` - the region for a Cloud SQL instance. We recommend using `us-central1`
- `[ZONE]` - the zone for a GKE cluster. We recommend using `us-central1-a`
- `[PREFIX]` - the name prefix that will be added to the names of provisioned resources
4. Review the logs generated by the script for any errors.

### Installing Kubeflow Pipelines components
1. Open **Cloud Shell**
2. Install **Kustomize** 
```
cd /usr/local/bin 
sudo wget https://github.com/kubernetes-sigs/kustomize/releases/download/kustomize%2Fv3.3.0/kustomize_v3.3.0_linux_amd64.tar.gz 
sudo tar xvf kustomize_v3.3.0_linux_amd64.tar.gz
sudo rm kustomize_v3.3.0_linux_amd64.tar.gz
```
3. Install Kubeflow Pipelines.  From the `/Lab-00-EnvironmentSetup/kfp` folder execute.
```
./deploy-kfp.sh  [PROJECT_ID] [NAMESPACE] [SQL_PASSWORD]
```
Where:
- `[PROJECT_ID]` - your project ID
- `[NAMESPACE]` - the namespace to host KFP components
- `[SQL_PASSWORD]` - the password for the Cloud SQL `root` user

*Note: The `deploy-kfp.sh` script does not allow you to specify a SQL username. The reason is that in the current versions of KFP the SQL username must be `root`*.

## Accessing KFP UI

After the installation completes, you can access the KFP UI from the following URL. You may need to wait a few minutes before the URL is operational.

```
echo "https://"$(kubectl describe configmap inverse-proxy-config -n kubeflow | grep "googleusercontent.com")
```

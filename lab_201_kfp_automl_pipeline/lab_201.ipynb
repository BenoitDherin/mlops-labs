{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestrating AutoML Tables training workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp.components import func_to_container_op\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare lab environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set lab settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jk-caip'\n",
    "DATASET_ID = 'lab_301'\n",
    "DATASET_LOCATION = 'US'\n",
    "TRANSACTIONS_TABLE_ID = 'transactions'\n",
    "TRANSACTIONS_TABLE_SCHEMA = 'customer_id:STRING,order_date:DATE,quantity:INTEGER,unit_price:FLOAT'\n",
    "TRANSACTIONS_SOURCE_FILE = '../datasets/clv/transactions.csv'\n",
    "CLUSTER_NAME = 'mlops5-cluster'\n",
    "CLUSTER_ZONE = 'us-central1-a'\n",
    "COMPONENT_URL_SEARCH_PREFIX = 'https://raw.githubusercontent.com/kubeflow/pipelines/0.1.33/components/gcp/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a BigQuery dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery error in mk operation: Dataset 'jk-caip:lab_301' already exists.\n"
     ]
    }
   ],
   "source": [
    "!bq --location=$DATASET_LOCATION --project_id=$PROJECT_ID mk --dataset $DATASET_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sale transactions data to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload complete.\n",
      "Waiting on bqjob_r42ef5cbf2ac46b0f_0000016e588a182c_1 ... (4s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "!bq --project_id=$PROJECT_ID --dataset_id=$DATASET_ID load \\\n",
    "--source_format=CSV \\\n",
    "--skip_leading_rows=1 \\\n",
    "--replace \\\n",
    "$TRANSACTIONS_TABLE_ID \\\n",
    "$TRANSACTIONS_SOURCE_FILE \\\n",
    "$TRANSACTIONS_TABLE_SCHEMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the KFP training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create component factories for the pre-defined GCP components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_store = kfp.components.ComponentStore(\n",
    "    local_search_paths=None,\n",
    "    url_search_prefixes=[COMPONENT_URL_SEARCH_PREFIX])\n",
    "    \n",
    "automl_create_dataset_op = component_store.load_component('automl/create_dataset_for_tables')\n",
    "automl_import_data_from_bq_op = component_store.load_component('automl/import_data_from_bigquery')\n",
    "automl_create_model__op = component_store.load_component('automl/create_model_for_tables')\n",
    "automl_split_dataset_table_column_names_op = component_store.load_component('automl/split_dataset_table_column_names')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create custom components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a base docker image for the custom components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM python:3.7\n",
    "RUN pip3 install --upgrade google-cloud-bigquery google-api-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 10 file(s) totalling 229.3 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://jk-caip_cloudbuild/source/1573442503.13-cdf51009c2e1441abf89702e072a1d28.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/jk-caip/builds/dca423db-12bf-4ba9-8920-48264b037d5e].\n",
      "Logs are available at [https://console.cloud.google.com/gcr/builds/dca423db-12bf-4ba9-8920-48264b037d5e?project=919618504923].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"dca423db-12bf-4ba9-8920-48264b037d5e\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://jk-caip_cloudbuild/source/1573442503.13-cdf51009c2e1441abf89702e072a1d28.tgz#1573442503567740\n",
      "Copying gs://jk-caip_cloudbuild/source/1573442503.13-cdf51009c2e1441abf89702e072a1d28.tgz#1573442503567740...\n",
      "/ [1 files][ 33.6 KiB/ 33.6 KiB]                                                \n",
      "Operation completed over 1 objects/33.6 KiB.                                     \n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  245.8kB\n",
      "Step 1/2 : FROM python:3.7\n",
      "3.7: Pulling from library/python\n",
      "c7b7d16361e0: Already exists\n",
      "b7a128769df1: Already exists\n",
      "1128949d0793: Already exists\n",
      "667692510b70: Already exists\n",
      "bed4ecf88e6a: Already exists\n",
      "8a8c75f3996a: Already exists\n",
      "8c90ed29fb66: Pulling fs layer\n",
      "984b0e9d1433: Pulling fs layer\n",
      "d930e1ce5d4a: Pulling fs layer\n",
      "d930e1ce5d4a: Verifying Checksum\n",
      "d930e1ce5d4a: Download complete\n",
      "984b0e9d1433: Verifying Checksum\n",
      "984b0e9d1433: Download complete\n",
      "8c90ed29fb66: Verifying Checksum\n",
      "8c90ed29fb66: Download complete\n",
      "8c90ed29fb66: Pull complete\n",
      "984b0e9d1433: Pull complete\n",
      "d930e1ce5d4a: Pull complete\n",
      "Digest: sha256:d182a775e372d82d92b59ff5debeabcb699964fe163320eb9fc5ebb971c51ec3\n",
      "Status: Downloaded newer image for python:3.7\n",
      " ---> 023b89039ba4\n",
      "Step 2/2 : RUN pip3 install --upgrade google-cloud-bigquery google-api-core\n",
      " ---> Running in 40e43761ce4f\n",
      "Collecting google-cloud-bigquery\n",
      "  Downloading https://files.pythonhosted.org/packages/b6/c6/bcfcb6c25e49d8ce10ccdf4358b7efef0fd729e0941e2d1966499a2fae2f/google_cloud_bigquery-1.21.0-py2.py3-none-any.whl (158kB)\n",
      "Collecting google-api-core\n",
      "  Downloading https://files.pythonhosted.org/packages/29/3a/c528ef37f48d6ffba16f0f3c0426456ba21e0dd32be9c61a2ade93e07faa/google_api_core-1.14.3-py2.py3-none-any.whl (68kB)\n",
      "Collecting protobuf>=3.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/34/02a2083afc14adff644a1e29783f276f12f1f914ca4cab157d73bb3d2fed/protobuf-3.10.0-cp37-cp37m-manylinux1_x86_64.whl (1.3MB)\n",
      "Collecting google-cloud-core<2.0dev,>=1.0.3\n",
      "  Downloading https://files.pythonhosted.org/packages/ee/f0/084f598629db8e6ec3627688723875cdb03637acb6d86999bb105a71df64/google_cloud_core-1.0.3-py2.py3-none-any.whl\n",
      "Collecting google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1\n",
      "  Downloading https://files.pythonhosted.org/packages/96/d7/b29a41b01b854480891dfc408211ffb0cc7a2a3d5f15a3b6740ec18c845b/google_resumable_media-0.4.1-py2.py3-none-any.whl\n",
      "Collecting pytz\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=34.0.0 in /usr/local/lib/python3.7/site-packages (from google-api-core) (41.4.0)\n",
      "Collecting google-auth<2.0dev,>=0.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/2f/81/d1e7d9974ba7c886f6d133a8baae18cb8d92b2d09bcc4f46328306825de0/google_auth-1.7.0-py2.py3-none-any.whl (74kB)\n",
      "Collecting six>=1.10.0\n",
      "  Downloading https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\n",
      "Collecting requests<3.0.0dev,>=2.18.0\n",
      "  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/ee/e59e74ecac678a14d6abefb9054f0bbcb318a6452a30df3776f133886d7d/googleapis-common-protos-1.6.0.tar.gz\n",
      "Collecting rsa<4.1,>=3.1.4\n",
      "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting cachetools<3.2,>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading https://files.pythonhosted.org/packages/52/50/bb4cefca37da63a0c52218ba2cb1b1c36110d84dcbae8aa48cd67c5e95c2/pyasn1_modules-0.2.7-py2.py3-none-any.whl (131kB)\n",
      "Collecting chardet<3.1.0,>=3.0.2\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading https://files.pythonhosted.org/packages/18/b0/8146a4f8dd402f60744fa380bc73ca47303cccf8b9190fd16a827281eac2/certifi-2019.9.11-py2.py3-none-any.whl (154kB)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading https://files.pythonhosted.org/packages/e0/da/55f51ea951e1b7c63a579c09dd7db825bb730ec1fe9c0180fc77bfb31448/urllib3-1.25.6-py2.py3-none-any.whl (125kB)\n",
      "Collecting idna<2.9,>=2.5\n",
      "  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/71/8f0d444e3a74e5640a3d5d967c1c6b015da9c655f35b2d308a55d907a517/pyasn1-0.4.7-py2.py3-none-any.whl (76kB)\n",
      "Building wheels for collected packages: googleapis-common-protos\n",
      "  Building wheel for googleapis-common-protos (setup.py): started\n",
      "  Building wheel for googleapis-common-protos (setup.py): finished with status 'done'\n",
      "  Created wheel for googleapis-common-protos: filename=googleapis_common_protos-1.6.0-cp37-none-any.whl size=77577 sha256=bd9538367d4371da838b4109e21ecab272b4f25d06f421785c8fcd574c493518\n",
      "  Stored in directory: /root/.cache/pip/wheels/9e/3d/a2/1bec8bb7db80ab3216dbc33092bb7ccd0debfb8ba42b5668d5\n",
      "Successfully built googleapis-common-protos\n",
      "Installing collected packages: six, protobuf, pytz, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, chardet, certifi, urllib3, idna, requests, googleapis-common-protos, google-api-core, google-cloud-core, google-resumable-media, google-cloud-bigquery\n",
      "Successfully installed cachetools-3.1.1 certifi-2019.9.11 chardet-3.0.4 google-api-core-1.14.3 google-auth-1.7.0 google-cloud-bigquery-1.21.0 google-cloud-core-1.0.3 google-resumable-media-0.4.1 googleapis-common-protos-1.6.0 idna-2.8 protobuf-3.10.0 pyasn1-0.4.7 pyasn1-modules-0.2.7 pytz-2019.3 requests-2.22.0 rsa-4.0 six-1.13.0 urllib3-1.25.6\n",
      "Removing intermediate container 40e43761ce4f\n",
      " ---> e4afe77f6568\n",
      "Successfully built e4afe77f6568\n",
      "Successfully tagged gcr.io/jk-caip/lab_301_components:latest\n",
      "PUSH\n",
      "Pushing gcr.io/jk-caip/lab_301_components:latest\n",
      "The push refers to repository [gcr.io/jk-caip/lab_301_components]\n",
      "006eca583ca0: Preparing\n",
      "8c40e5337dcd: Preparing\n",
      "978eb45ee4b6: Preparing\n",
      "3f53405f239c: Preparing\n",
      "48ebd1638acd: Preparing\n",
      "31f78d833a92: Preparing\n",
      "2ea751c0f96c: Preparing\n",
      "7a435d49206f: Preparing\n",
      "9674e3075904: Preparing\n",
      "831b66a484dc: Preparing\n",
      "31f78d833a92: Waiting\n",
      "2ea751c0f96c: Waiting\n",
      "7a435d49206f: Waiting\n",
      "9674e3075904: Waiting\n",
      "831b66a484dc: Waiting\n",
      "3f53405f239c: Layer already exists\n",
      "48ebd1638acd: Layer already exists\n",
      "8c40e5337dcd: Layer already exists\n",
      "978eb45ee4b6: Layer already exists\n",
      "31f78d833a92: Layer already exists\n",
      "9674e3075904: Layer already exists\n",
      "2ea751c0f96c: Layer already exists\n",
      "7a435d49206f: Layer already exists\n",
      "831b66a484dc: Layer already exists\n",
      "006eca583ca0: Pushed\n",
      "latest: digest: sha256:d4cdd42798cfc98127de5ec7e7000dbe78920204e2d26d9ff43e393083c8133f size: 2428\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                             IMAGES                                       STATUS\n",
      "dca423db-12bf-4ba9-8920-48264b037d5e  2019-11-11T03:21:44+00:00  31S       gs://jk-caip_cloudbuild/source/1573442503.13-cdf51009c2e1441abf89702e072a1d28.tgz  gcr.io/jk-caip/lab_301_components (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "IMAGE_NAME=\"lab_301_components\"\n",
    "IMAGE_URI=\"gcr.io/{}/{}:latest\".format(PROJECT_ID, IMAGE_NAME)\n",
    "!gcloud builds submit --timeout 15m --tag $IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create BQ query component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bq_query(query: str, \n",
    "             project_id:str, \n",
    "             dataset_id: str, \n",
    "             table_id: str, \n",
    "             location: str) -> NamedTuple('Outputs', [('table_reference', str), ('job_id', str)]):\n",
    "\n",
    "    from google.cloud import bigquery\n",
    "    from google.api_core import exceptions\n",
    "    import logging\n",
    "    import os\n",
    "    import uuid\n",
    "    \n",
    "    KFP_POD_ENV_NAME = 'KFP_POD_NAME'\n",
    "    DEFAULT_DATASET_ID = 'lab_301'\n",
    "    \n",
    "    def _prepare_dataset_ref(client, dataset_id, location):\n",
    "        if not dataset_id:\n",
    "            dataset_id = DEFAULT_DATASET_ID\n",
    "        dataset_ref = client.dataset(dataset_id)\n",
    "        try:\n",
    "            dataset = client.get_dataset(dataset_ref)\n",
    "        except exceptions.NotFound:\n",
    "            dataset = bigquery.Dataset(dataset_ref)\n",
    "            dataset.location = location\n",
    "            logging.info('Creating dataset {}'.format(dataset_id))\n",
    "            client.create_dataset(dataset)\n",
    "        \n",
    "        return dataset_ref\n",
    "\n",
    "    def _get_job(client, job_id):\n",
    "        try:\n",
    "            return client.get_job(job_id)\n",
    "        except exceptions.NotFound:\n",
    "            return None\n",
    "    \n",
    "    client = bigquery.Client(project=project_id, location=location)\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    job_config.create_disposition = bigquery.job.CreateDisposition.CREATE_IF_NEEDED\n",
    "    job_config.write_disposition = bigquery.job.WriteDisposition.WRITE_TRUNCATE\n",
    "    job_id = 'query_' + os.environ.get(KFP_POD_ENV_NAME, uuid.uuid1().hex)\n",
    "     \n",
    "    if not _get_job(client, job_id):\n",
    "        dataset_ref = _prepare_dataset_ref(client, dataset_id, location)\n",
    "        if not table_id:\n",
    "            table_id = job_id\n",
    "        table_ref = dataset_ref.table(table_id)\n",
    "        job_config.destination = table_ref\n",
    "        logging.info('Submitting the jobL {}'.format(job_id))\n",
    "        query_job = client.query(query, job_config, job_id=job_id)\n",
    "        query_job.result() # Wait for query to finish\n",
    "            \n",
    "    \n",
    "    return (table_ref.path, job_id)\n",
    "    \n",
    "bq_query_op = func_to_container_op(bq_query, base_image='gcr.io/jk-caip/lab_301_components:latest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the pipeline\n",
    "#### Set default values for pipeline parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "_project_id = PROJECT_ID\n",
    "_features_dataset_id = DATASET_ID\n",
    "_features_dataset_location = DATASET_LOCATION\n",
    "_features_table_id = 'features'\n",
    "_aml_compute_region = 'us-central1'\n",
    "_aml_dataset_name = 'clv_features'\n",
    "_aml_model_name = 'clv_regression'\n",
    "_target_column_name = 'target_monetary'\n",
    "_train_budget = 1000\n",
    "_optimization_objective = 'MINIMIZE_MAE'\n",
    "_primary_metric = 'mean_absolute_error'\n",
    "_deployment_threshold = 900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set a default feature engineering query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "\n",
    "_query_template = '''\n",
    "WITH\n",
    "  order_summaries as (\n",
    "    SELECT\n",
    "      a.customer_id,\n",
    "      a.order_date,\n",
    "      a.order_value,\n",
    "      a.order_qty_articles\n",
    "    FROM\n",
    "    (\n",
    "      SELECT\n",
    "        customer_id,\n",
    "        order_date,\n",
    "        ROUND(SUM(unit_price * quantity), 2) AS order_value,\n",
    "        SUM(quantity) AS order_qty_articles,\n",
    "        (\n",
    "          SELECT\n",
    "            MAX(order_date)\n",
    "          FROM\n",
    "            `{{ data_source_id }}` tl\n",
    "          WHERE\n",
    "            tl.customer_id = t.customer_id\n",
    "        ) latest_order\n",
    "      FROM\n",
    "        `{{ data_source_id }}` t\n",
    "      GROUP BY\n",
    "          customer_id,\n",
    "          order_date\n",
    "    ) a\n",
    "\n",
    "    INNER JOIN (\n",
    "      -- Only customers with more than one positive order values before threshold.\n",
    "      SELECT\n",
    "        customer_id\n",
    "      FROM (\n",
    "        -- Customers and how many positive order values  before threshold.\n",
    "        SELECT\n",
    "          customer_id,\n",
    "          SUM(positive_value) cnt_positive_value\n",
    "        FROM (\n",
    "          -- Customer with whether order was positive or not at each date.\n",
    "          SELECT\n",
    "            customer_id,\n",
    "            (\n",
    "              CASE\n",
    "                WHEN SUM(unit_price * quantity) > 0 THEN 1\n",
    "                ELSE 0\n",
    "              END ) positive_value\n",
    "          FROM\n",
    "            `{{ data_source_id }}`\n",
    "          WHERE\n",
    "            order_date < DATE(\"{{ threshold_date }}\")\n",
    "          GROUP BY\n",
    "            customer_id,\n",
    "            order_date)\n",
    "        GROUP BY\n",
    "          customer_id )\n",
    "      WHERE\n",
    "        cnt_positive_value > 1\n",
    "      ) b\n",
    "    ON\n",
    "      a.customer_id = b.customer_id\n",
    "    --[START common_clean]\n",
    "    WHERE\n",
    "      -- Bought in the past 3 months\n",
    "      DATE_DIFF(DATE(\"{{ predict_end }}\"), latest_order, DAY) <= 90\n",
    "      -- Make sure returns are consistent.\n",
    "      AND (\n",
    "        (order_qty_articles > 0 and order_Value > 0) OR\n",
    "        (order_qty_articles < 0 and order_Value < 0)\n",
    "      ))\n",
    "          \n",
    "SELECT\n",
    "  tf.customer_id,\n",
    "  -- For training period\n",
    "  -- Copying the calculations from Lifetimes where first orders are ignored\n",
    "  -- See https://github.com/CamDavidsonPilon/lifetimes/blob/master/lifetimes/utils.py#L246\n",
    "--[START features_target]\n",
    "  ROUND(tf.monetary, 2) as monetary,\n",
    "  tf.cnt_orders AS frequency,\n",
    "  tf.recency,\n",
    "  tf.T,\n",
    "  ROUND(tf.recency/cnt_orders, 2) AS time_between,\n",
    "  ROUND(tf.avg_basket_value, 2) AS avg_basket_value,\n",
    "  ROUND(tf.avg_basket_size, 2) AS avg_basket_size,\n",
    "  tf.cnt_returns,\n",
    "  -- Target calculated for overall period\n",
    "  ROUND(tt.target_monetary, 2) as target_monetary\n",
    "--[END features_target]\n",
    "FROM\n",
    "  -- This SELECT uses only data before threshold to make features.\n",
    "  (\n",
    "    SELECT\n",
    "      customer_id,\n",
    "      SUM(order_value) AS monetary,\n",
    "      DATE_DIFF(MAX(order_date), MIN(order_date), DAY) AS recency,\n",
    "      DATE_DIFF(DATE('{{ threshold_date }}'), MIN(order_date), DAY) AS T,\n",
    "      COUNT(DISTINCT order_date) AS cnt_orders,\n",
    "      AVG(order_qty_articles) avg_basket_size,\n",
    "      AVG(order_value) avg_basket_value,\n",
    "      SUM(CASE\n",
    "          WHEN order_value < 1 THEN 1\n",
    "          ELSE 0 END) AS cnt_returns\n",
    "    FROM\n",
    "      order_summaries a\n",
    "    WHERE\n",
    "      order_date <= DATE('{{ threshold_date }}')\n",
    "    GROUP BY\n",
    "      customer_id) tf,\n",
    "\n",
    "  -- This SELECT uses data after threshold to calculate the target )\n",
    "  (\n",
    "    SELECT\n",
    "      customer_id,\n",
    "      SUM(order_value) target_monetary\n",
    "    FROM\n",
    "      order_summaries\n",
    "      WHERE order_date > DATE('{{ threshold_date }}')\n",
    "    GROUP BY\n",
    "      customer_id) tt\n",
    "WHERE\n",
    "  tf.customer_id = tt.customer_id\n",
    "  AND tf.monetary > 0\n",
    "  AND tf.monetary <= {{ max_monetary }}\n",
    "'''\n",
    "\n",
    "_query = Template(_query_template).render(\n",
    "    data_source_id='{}.{}.{}'.format(PROJECT_ID, DATASET_ID, TRANSACTIONS_TABLE_ID),\n",
    "    threshold_date='2011-08-08',\n",
    "    predict_end='2011-12-12',\n",
    "    max_monetary=15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the pipeline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name='CLV Training',\n",
    "    description='CLV Training Pipeline using BigQuery for feature engineering and Automl Tables for model training'\n",
    ")\n",
    "def clv_train(\n",
    "    project_id:str =_project_id,\n",
    "    feature_engineering_query:str =_query,\n",
    "    aml_compute_region:str =_aml_compute_region,\n",
    "    features_table_id:str =_features_table_id,\n",
    "    features_dataset_id:str =_features_dataset_id,\n",
    "    features_dataset_location:str =_features_dataset_location,\n",
    "    aml_dataset_name:str =_aml_dataset_name,\n",
    "    target_column_name:str =_target_column_name,\n",
    "    aml_model_name:str =_aml_model_name,\n",
    "    train_budget:int =_train_budget,\n",
    "    primary_metric:float =_primary_metric,\n",
    "    deployment_threshold:float =_deployment_threshold\n",
    "    ):\n",
    "    \n",
    "    engineer_features = bq_query_op(\n",
    "        query=feature_engineering_query,\n",
    "        project_id=project_id,\n",
    "        dataset_id=features_dataset_id,\n",
    "        table_id=features_table_id,\n",
    "        location=features_dataset_location)\n",
    "    \n",
    "    from kfp.gcp import use_gcp_secret\n",
    "    kfp.dsl.get_pipeline_conf().add_op_transformer(use_gcp_secret('user-gcp-sa'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pipeline_yaml = 'clv_training.yaml'\n",
    "kfp.compiler.Compiler().compile(clv_train, _pipeline_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the pipeline to KFP\n",
    "Get GKE cluster credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Fetching cluster endpoint and auth data.\n",
      "kubeconfig entry generated for mlops5-cluster.\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set project $PROJECT_ID\n",
    "!gcloud container clusters get-credentials $CLUSTER_NAME --zone $CLUSTER_ZONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `kfp.Client()` to upload the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Pipeline link <a href=/pipeline/#/pipelines/details/98af5f51-51a5-41b0-bd77-747b233a8fc8>here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_pipeline_name = 'clv_training_pipeline'\n",
    "_client = kfp.Client()\n",
    "\n",
    "\n",
    "pipelines = [pipeline for pipeline in _client.list_pipelines(page_size=100).pipelines if pipeline.name == _pipeline_name]\n",
    "\n",
    "if pipelines:\n",
    "    print(\"Pipeline with this name already exists\")\n",
    "    _pipeline_ref = pipelines[0]\n",
    "    \n",
    "else:\n",
    "    _pipeline_ref = _client.upload_pipeline(_pipeline_yaml, _pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigger a pipeline run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/3fa9384c-b36c-46b5-8e96-64fdd549c1fe\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/033bde69-3689-4131-94aa-f1089ef8dcfb\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'created_at': datetime.datetime(2019, 11, 11, 3, 36, 56, tzinfo=tzlocal()),\n",
       " 'description': None,\n",
       " 'error': None,\n",
       " 'finished_at': datetime.datetime(1970, 1, 1, 0, 0, tzinfo=tzlocal()),\n",
       " 'id': '033bde69-3689-4131-94aa-f1089ef8dcfb',\n",
       " 'metrics': None,\n",
       " 'name': 'Run 01',\n",
       " 'pipeline_spec': {'parameters': None,\n",
       "                   'pipeline_id': '98af5f51-51a5-41b0-bd77-747b233a8fc8',\n",
       "                   'pipeline_manifest': None,\n",
       "                   'workflow_manifest': '{\"kind\":\"Workflow\",\"apiVersion\":\"argoproj.io/v1alpha1\",\"metadata\":{\"generateName\":\"clv-training-\",\"creationTimestamp\":null,\"annotations\":{\"pipelines.kubeflow.org/pipeline_spec\":\"{\\\\\"description\\\\\": '\n",
       "                                        '\\\\\"CLV Training Pipeline using '\n",
       "                                        'BigQuery for feature engineering and '\n",
       "                                        'Automl Tables for model training\\\\\", '\n",
       "                                        '\\\\\"inputs\\\\\": [{\\\\\"default\\\\\": '\n",
       "                                        '\\\\\"jk-caip\\\\\", \\\\\"name\\\\\": '\n",
       "                                        '\\\\\"project_id\\\\\"}, {\\\\\"default\\\\\": '\n",
       "                                        '\\\\\"\\\\\\\\nWITH\\\\\\\\n  order_summaries as '\n",
       "                                        '(\\\\\\\\n    SELECT\\\\\\\\n      '\n",
       "                                        'a.customer_id,\\\\\\\\n      '\n",
       "                                        'a.order_date,\\\\\\\\n      '\n",
       "                                        'a.order_value,\\\\\\\\n      '\n",
       "                                        'a.order_qty_articles\\\\\\\\n    '\n",
       "                                        'FROM\\\\\\\\n    (\\\\\\\\n      '\n",
       "                                        'SELECT\\\\\\\\n        '\n",
       "                                        'customer_id,\\\\\\\\n        '\n",
       "                                        'order_date,\\\\\\\\n        '\n",
       "                                        'ROUND(SUM(unit_price * quantity), 2) '\n",
       "                                        'AS order_value,\\\\\\\\n        '\n",
       "                                        'SUM(quantity) AS '\n",
       "                                        'order_qty_articles,\\\\\\\\n        '\n",
       "                                        '(\\\\\\\\n          '\n",
       "                                        'SELECT\\\\\\\\n            '\n",
       "                                        'MAX(order_date)\\\\\\\\n          '\n",
       "                                        'FROM\\\\\\\\n            '\n",
       "                                        '`jk-caip.lab_301.transactions` '\n",
       "                                        'tl\\\\\\\\n          '\n",
       "                                        'WHERE\\\\\\\\n            tl.customer_id '\n",
       "                                        '= t.customer_id\\\\\\\\n        ) '\n",
       "                                        'latest_order\\\\\\\\n      '\n",
       "                                        'FROM\\\\\\\\n        '\n",
       "                                        '`jk-caip.lab_301.transactions` '\n",
       "                                        't\\\\\\\\n      GROUP BY\\\\\\\\n          '\n",
       "                                        'customer_id,\\\\\\\\n          '\n",
       "                                        'order_date\\\\\\\\n    ) a\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'INNER JOIN (\\\\\\\\n      -- Only '\n",
       "                                        'customers with more than one positive '\n",
       "                                        'order values before '\n",
       "                                        'threshold.\\\\\\\\n      '\n",
       "                                        'SELECT\\\\\\\\n        '\n",
       "                                        'customer_id\\\\\\\\n      FROM '\n",
       "                                        '(\\\\\\\\n        -- Customers and how '\n",
       "                                        'many positive order values  before '\n",
       "                                        'threshold.\\\\\\\\n        '\n",
       "                                        'SELECT\\\\\\\\n          '\n",
       "                                        'customer_id,\\\\\\\\n          '\n",
       "                                        'SUM(positive_value) '\n",
       "                                        'cnt_positive_value\\\\\\\\n        FROM '\n",
       "                                        '(\\\\\\\\n          -- Customer with '\n",
       "                                        'whether order was positive or not at '\n",
       "                                        'each date.\\\\\\\\n          '\n",
       "                                        'SELECT\\\\\\\\n            '\n",
       "                                        'customer_id,\\\\\\\\n            '\n",
       "                                        '(\\\\\\\\n              '\n",
       "                                        'CASE\\\\\\\\n                WHEN '\n",
       "                                        'SUM(unit_price * quantity) \\\\u003e 0 '\n",
       "                                        'THEN 1\\\\\\\\n                ELSE '\n",
       "                                        '0\\\\\\\\n              END ) '\n",
       "                                        'positive_value\\\\\\\\n          '\n",
       "                                        'FROM\\\\\\\\n            '\n",
       "                                        '`jk-caip.lab_301.transactions`\\\\\\\\n          '\n",
       "                                        'WHERE\\\\\\\\n            order_date '\n",
       "                                        '\\\\u003c '\n",
       "                                        'DATE(\\\\\\\\\\\\\"2011-08-08\\\\\\\\\\\\\")\\\\\\\\n          '\n",
       "                                        'GROUP BY\\\\\\\\n            '\n",
       "                                        'customer_id,\\\\\\\\n            '\n",
       "                                        'order_date)\\\\\\\\n        GROUP '\n",
       "                                        'BY\\\\\\\\n          customer_id '\n",
       "                                        ')\\\\\\\\n      WHERE\\\\\\\\n        '\n",
       "                                        'cnt_positive_value \\\\u003e '\n",
       "                                        '1\\\\\\\\n      ) b\\\\\\\\n    ON\\\\\\\\n      '\n",
       "                                        'a.customer_id = b.customer_id\\\\\\\\n    '\n",
       "                                        '--[START common_clean]\\\\\\\\n    '\n",
       "                                        'WHERE\\\\\\\\n      -- Bought in the past '\n",
       "                                        '3 months\\\\\\\\n      '\n",
       "                                        'DATE_DIFF(DATE(\\\\\\\\\\\\\"2011-12-12\\\\\\\\\\\\\"), '\n",
       "                                        'latest_order, DAY) \\\\u003c= '\n",
       "                                        '90\\\\\\\\n      -- Make sure returns are '\n",
       "                                        'consistent.\\\\\\\\n      AND '\n",
       "                                        '(\\\\\\\\n        (order_qty_articles '\n",
       "                                        '\\\\u003e 0 and order_Value \\\\u003e 0) '\n",
       "                                        'OR\\\\\\\\n        (order_qty_articles '\n",
       "                                        '\\\\u003c 0 and order_Value \\\\u003c '\n",
       "                                        '0)\\\\\\\\n      ))\\\\\\\\n          '\n",
       "                                        '\\\\\\\\nSELECT\\\\\\\\n  '\n",
       "                                        'tf.customer_id,\\\\\\\\n  -- For training '\n",
       "                                        'period\\\\\\\\n  -- Copying the '\n",
       "                                        'calculations from Lifetimes where '\n",
       "                                        'first orders are ignored\\\\\\\\n  -- See '\n",
       "                                        'https://github.com/CamDavidsonPilon/lifetimes/blob/master/lifetimes/utils.py#L246\\\\\\\\n--[START '\n",
       "                                        'features_target]\\\\\\\\n  '\n",
       "                                        'ROUND(tf.monetary, 2) as '\n",
       "                                        'monetary,\\\\\\\\n  tf.cnt_orders AS '\n",
       "                                        'frequency,\\\\\\\\n  tf.recency,\\\\\\\\n  '\n",
       "                                        'tf.T,\\\\\\\\n  '\n",
       "                                        'ROUND(tf.recency/cnt_orders, 2) AS '\n",
       "                                        'time_between,\\\\\\\\n  '\n",
       "                                        'ROUND(tf.avg_basket_value, 2) AS '\n",
       "                                        'avg_basket_value,\\\\\\\\n  '\n",
       "                                        'ROUND(tf.avg_basket_size, 2) AS '\n",
       "                                        'avg_basket_size,\\\\\\\\n  '\n",
       "                                        'tf.cnt_returns,\\\\\\\\n  -- Target '\n",
       "                                        'calculated for overall period\\\\\\\\n  '\n",
       "                                        'ROUND(tt.target_monetary, 2) as '\n",
       "                                        'target_monetary\\\\\\\\n--[END '\n",
       "                                        'features_target]\\\\\\\\nFROM\\\\\\\\n  -- '\n",
       "                                        'This SELECT uses only data before '\n",
       "                                        'threshold to make features.\\\\\\\\n  '\n",
       "                                        '(\\\\\\\\n    SELECT\\\\\\\\n      '\n",
       "                                        'customer_id,\\\\\\\\n      '\n",
       "                                        'SUM(order_value) AS '\n",
       "                                        'monetary,\\\\\\\\n      '\n",
       "                                        'DATE_DIFF(MAX(order_date), '\n",
       "                                        'MIN(order_date), DAY) AS '\n",
       "                                        'recency,\\\\\\\\n      '\n",
       "                                        \"DATE_DIFF(DATE('2011-08-08'), \"\n",
       "                                        'MIN(order_date), DAY) AS T,\\\\\\\\n      '\n",
       "                                        'COUNT(DISTINCT order_date) AS '\n",
       "                                        'cnt_orders,\\\\\\\\n      '\n",
       "                                        'AVG(order_qty_articles) '\n",
       "                                        'avg_basket_size,\\\\\\\\n      '\n",
       "                                        'AVG(order_value) '\n",
       "                                        'avg_basket_value,\\\\\\\\n      '\n",
       "                                        'SUM(CASE\\\\\\\\n          WHEN '\n",
       "                                        'order_value \\\\u003c 1 THEN '\n",
       "                                        '1\\\\\\\\n          ELSE 0 END) AS '\n",
       "                                        'cnt_returns\\\\\\\\n    FROM\\\\\\\\n      '\n",
       "                                        'order_summaries a\\\\\\\\n    '\n",
       "                                        'WHERE\\\\\\\\n      order_date \\\\u003c= '\n",
       "                                        \"DATE('2011-08-08')\\\\\\\\n    GROUP \"\n",
       "                                        'BY\\\\\\\\n      customer_id) '\n",
       "                                        'tf,\\\\\\\\n\\\\\\\\n  -- This SELECT uses '\n",
       "                                        'data after threshold to calculate the '\n",
       "                                        'target )\\\\\\\\n  (\\\\\\\\n    '\n",
       "                                        'SELECT\\\\\\\\n      '\n",
       "                                        'customer_id,\\\\\\\\n      '\n",
       "                                        'SUM(order_value) '\n",
       "                                        'target_monetary\\\\\\\\n    '\n",
       "                                        'FROM\\\\\\\\n      '\n",
       "                                        'order_summaries\\\\\\\\n      WHERE '\n",
       "                                        'order_date \\\\u003e '\n",
       "                                        \"DATE('2011-08-08')\\\\\\\\n    GROUP \"\n",
       "                                        'BY\\\\\\\\n      customer_id) '\n",
       "                                        'tt\\\\\\\\nWHERE\\\\\\\\n  tf.customer_id = '\n",
       "                                        'tt.customer_id\\\\\\\\n  AND tf.monetary '\n",
       "                                        '\\\\u003e 0\\\\\\\\n  AND tf.monetary '\n",
       "                                        '\\\\u003c= 15000\\\\\", \\\\\"name\\\\\": '\n",
       "                                        '\\\\\"feature_engineering_query\\\\\"}, '\n",
       "                                        '{\\\\\"default\\\\\": \\\\\"us-central1\\\\\", '\n",
       "                                        '\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"aml_compute_region\\\\\"}, '\n",
       "                                        '{\\\\\"default\\\\\": \\\\\"features\\\\\", '\n",
       "                                        '\\\\\"name\\\\\": \\\\\"features_table_id\\\\\"}, '\n",
       "                                        '{\\\\\"default\\\\\": \\\\\"lab_301\\\\\", '\n",
       "                                        '\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"features_dataset_id\\\\\"}, '\n",
       "                                        '{\\\\\"default\\\\\": \\\\\"US\\\\\", \\\\\"name\\\\\": '\n",
       "                                        '\\\\\"features_dataset_location\\\\\"}, '\n",
       "                                        '{\\\\\"default\\\\\": \\\\\"clv_features\\\\\", '\n",
       "                                        '\\\\\"name\\\\\": \\\\\"aml_dataset_name\\\\\"}, '\n",
       "                                        '{\\\\\"default\\\\\": '\n",
       "                                        '\\\\\"target_monetary\\\\\", \\\\\"name\\\\\": '\n",
       "                                        '\\\\\"target_column_name\\\\\"}, '\n",
       "                                        '{\\\\\"default\\\\\": \\\\\"clv_regression\\\\\", '\n",
       "                                        '\\\\\"name\\\\\": \\\\\"aml_model_name\\\\\"}, '\n",
       "                                        '{\\\\\"default\\\\\": \\\\\"1000\\\\\", '\n",
       "                                        '\\\\\"name\\\\\": \\\\\"train_budget\\\\\"}, '\n",
       "                                        '{\\\\\"default\\\\\": '\n",
       "                                        '\\\\\"mean_absolute_error\\\\\", '\n",
       "                                        '\\\\\"name\\\\\": \\\\\"primary_metric\\\\\"}, '\n",
       "                                        '{\\\\\"default\\\\\": \\\\\"900\\\\\", '\n",
       "                                        '\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"deployment_threshold\\\\\"}], '\n",
       "                                        '\\\\\"name\\\\\": \\\\\"CLV '\n",
       "                                        'Training\\\\\"}\"}},\"spec\":{\"templates\":[{\"name\":\"bq-query\",\"inputs\":{\"parameters\":[{\"name\":\"feature-engineering-query\"},{\"name\":\"features-dataset-id\"},{\"name\":\"features-dataset-location\"},{\"name\":\"features-table-id\"},{\"name\":\"project-id\"}]},\"outputs\":{\"artifacts\":[{\"name\":\"bq-query-job-id\",\"path\":\"/tmp/outputs/job_id/data\"},{\"name\":\"bq-query-table-reference\",\"path\":\"/tmp/outputs/table_reference/data\"}]},\"metadata\":{\"annotations\":{\"pipelines.kubeflow.org/component_spec\":\"{\\\\\"inputs\\\\\": '\n",
       "                                        '[{\\\\\"name\\\\\": \\\\\"query\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"String\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": \\\\\"project_id\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"String\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": \\\\\"dataset_id\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"String\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": \\\\\"table_id\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"String\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": \\\\\"location\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"String\\\\\"}], '\n",
       "                                        '\\\\\"name\\\\\": \\\\\"Bq query\\\\\", '\n",
       "                                        '\\\\\"outputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"table_reference\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"job_id\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}]}\"}},\"container\":{\"name\":\"\",\"image\":\"gcr.io/jk-caip/lab_301_components:latest\",\"command\":[\"python3\",\"-u\",\"-c\",\"from '\n",
       "                                        'typing import NamedTuple\\\\n\\\\ndef '\n",
       "                                        'bq_query(query: str, \\\\n             '\n",
       "                                        'project_id:str, \\\\n             '\n",
       "                                        'dataset_id: str, \\\\n             '\n",
       "                                        'table_id: str, \\\\n             '\n",
       "                                        'location: str) -\\\\u003e '\n",
       "                                        \"NamedTuple('Outputs', \"\n",
       "                                        \"[('table_reference', str), ('job_id', \"\n",
       "                                        'str)]):\\\\n\\\\n    from google.cloud '\n",
       "                                        'import bigquery\\\\n    from '\n",
       "                                        'google.api_core import '\n",
       "                                        'exceptions\\\\n    import logging\\\\n    '\n",
       "                                        'import os\\\\n    import uuid\\\\n\\\\n    '\n",
       "                                        'KFP_POD_ENV_NAME = '\n",
       "                                        \"'KFP_POD_NAME'\\\\n    \"\n",
       "                                        'DEFAULT_DATASET_ID = '\n",
       "                                        \"'lab_301'\\\\n\\\\n    def \"\n",
       "                                        '_prepare_dataset_ref(client, '\n",
       "                                        'dataset_id, location):\\\\n        if '\n",
       "                                        'not dataset_id:\\\\n            '\n",
       "                                        'dataset_id = '\n",
       "                                        'DEFAULT_DATASET_ID\\\\n        '\n",
       "                                        'dataset_ref = '\n",
       "                                        'client.dataset(dataset_id)\\\\n        '\n",
       "                                        'try:\\\\n            dataset = '\n",
       "                                        'client.get_dataset(dataset_ref)\\\\n        '\n",
       "                                        'except '\n",
       "                                        'exceptions.NotFound:\\\\n            '\n",
       "                                        'dataset = '\n",
       "                                        'bigquery.Dataset(dataset_ref)\\\\n            '\n",
       "                                        'dataset.location = '\n",
       "                                        'location\\\\n            '\n",
       "                                        \"logging.info('Creating dataset \"\n",
       "                                        \"{}'.format(dataset_id))\\\\n            \"\n",
       "                                        'client.create_dataset(dataset)\\\\n\\\\n        '\n",
       "                                        'return dataset_ref\\\\n\\\\n    def '\n",
       "                                        '_get_job(client, job_id):\\\\n        '\n",
       "                                        'try:\\\\n            return '\n",
       "                                        'client.get_job(job_id)\\\\n        '\n",
       "                                        'except '\n",
       "                                        'exceptions.NotFound:\\\\n            '\n",
       "                                        'return None\\\\n\\\\n    client = '\n",
       "                                        'bigquery.Client(project=project_id, '\n",
       "                                        'location=location)\\\\n    job_config = '\n",
       "                                        'bigquery.QueryJobConfig()\\\\n    '\n",
       "                                        'job_config.create_disposition = '\n",
       "                                        'bigquery.job.CreateDisposition.CREATE_IF_NEEDED\\\\n    '\n",
       "                                        'job_config.write_disposition = '\n",
       "                                        'bigquery.job.WriteDisposition.WRITE_TRUNCATE\\\\n    '\n",
       "                                        \"job_id = 'query_' + \"\n",
       "                                        'os.environ.get(KFP_POD_ENV_NAME, '\n",
       "                                        'uuid.uuid1().hex)\\\\n\\\\n    if not '\n",
       "                                        '_get_job(client, job_id):\\\\n        '\n",
       "                                        'dataset_ref = '\n",
       "                                        '_prepare_dataset_ref(client, '\n",
       "                                        'dataset_id, location)\\\\n        if '\n",
       "                                        'not table_id:\\\\n            table_id '\n",
       "                                        '= job_id\\\\n        table_ref = '\n",
       "                                        'dataset_ref.table(table_id)\\\\n        '\n",
       "                                        'job_config.destination = '\n",
       "                                        'table_ref\\\\n        '\n",
       "                                        \"logging.info('Submitting the jobL \"\n",
       "                                        \"{}'.format(job_id))\\\\n        \"\n",
       "                                        'query_job = client.query(query, '\n",
       "                                        'job_config, job_id=job_id)\\\\n        '\n",
       "                                        'query_job.result() # Wait for query '\n",
       "                                        'to finish\\\\n\\\\n    return '\n",
       "                                        '(table_ref.path, job_id)\\\\n\\\\ndef '\n",
       "                                        '_serialize_str(str_value: str) '\n",
       "                                        '-\\\\u003e str:\\\\n    if not '\n",
       "                                        'isinstance(str_value, str):\\\\n        '\n",
       "                                        'raise TypeError(\\'Value \\\\\"{}\\\\\" has '\n",
       "                                        'type \\\\\"{}\\\\\" instead of '\n",
       "                                        \"str.'.format(str(str_value), \"\n",
       "                                        'str(type(str_value))))\\\\n    return '\n",
       "                                        'str_value\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Bq \"\n",
       "                                        \"query', \"\n",
       "                                        'description=\\'\\')\\\\n_parser.add_argument(\\\\\"--query\\\\\", '\n",
       "                                        'dest=\\\\\"query\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--project-id\\\\\", '\n",
       "                                        'dest=\\\\\"project_id\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--dataset-id\\\\\", '\n",
       "                                        'dest=\\\\\"dataset_id\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--table-id\\\\\", '\n",
       "                                        'dest=\\\\\"table_id\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--location\\\\\", '\n",
       "                                        'dest=\\\\\"location\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"----output-paths\\\\\", '\n",
       "                                        'dest=\\\\\"_output_paths\\\\\", type=str, '\n",
       "                                        'nargs=2)\\\\n_parsed_args = '\n",
       "                                        'vars(_parser.parse_args())\\\\n_output_files '\n",
       "                                        '= '\n",
       "                                        '_parsed_args.pop(\\\\\"_output_paths\\\\\", '\n",
       "                                        '[])\\\\n\\\\n_outputs = '\n",
       "                                        'bq_query(**_parsed_args)\\\\n\\\\nif not '\n",
       "                                        \"hasattr(_outputs, '__getitem__') or \"\n",
       "                                        'isinstance(_outputs, str):\\\\n    '\n",
       "                                        '_outputs = '\n",
       "                                        '[_outputs]\\\\n\\\\n_output_serializers = '\n",
       "                                        '[\\\\n    _serialize_str,\\\\n    '\n",
       "                                        '_serialize_str\\\\n]\\\\n\\\\nimport '\n",
       "                                        'os\\\\nfor idx, output_file in '\n",
       "                                        'enumerate(_output_files):\\\\n    '\n",
       "                                        'try:\\\\n        '\n",
       "                                        'os.makedirs(os.path.dirname(output_file))\\\\n    '\n",
       "                                        'except OSError:\\\\n        pass\\\\n    '\n",
       "                                        \"with open(output_file, 'w') as \"\n",
       "                                        'f:\\\\n        '\n",
       "                                        'f.write(_output_serializers[idx](_outputs[idx]))\\\\n\"],\"args\":[\"--query\",\"{{inputs.parameters.feature-engineering-query}}\",\"--project-id\",\"{{inputs.parameters.project-id}}\",\"--dataset-id\",\"{{inputs.parameters.features-dataset-id}}\",\"--table-id\",\"{{inputs.parameters.features-table-id}}\",\"--location\",\"{{inputs.parameters.features-dataset-location}}\",\"----output-paths\",\"/tmp/outputs/table_reference/data\",\"/tmp/outputs/job_id/data\"],\"env\":[{\"name\":\"GOOGLE_APPLICATION_CREDENTIALS\",\"value\":\"/secret/gcp-credentials/user-gcp-sa.json\"},{\"name\":\"CLOUDSDK_AUTH_CREDENTIAL_FILE_OVERRIDE\",\"value\":\"/secret/gcp-credentials/user-gcp-sa.json\"}],\"resources\":{},\"volumeMounts\":[{\"name\":\"gcp-credentials-user-gcp-sa\",\"mountPath\":\"/secret/gcp-credentials\"}]},\"volumes\":[{\"name\":\"gcp-credentials-user-gcp-sa\",\"secret\":{\"secretName\":\"user-gcp-sa\"}}]},{\"name\":\"clv-training\",\"inputs\":{\"parameters\":[{\"name\":\"feature-engineering-query\"},{\"name\":\"features-dataset-id\"},{\"name\":\"features-dataset-location\"},{\"name\":\"features-table-id\"},{\"name\":\"project-id\"}]},\"outputs\":{},\"metadata\":{},\"dag\":{\"tasks\":[{\"name\":\"bq-query\",\"template\":\"bq-query\",\"arguments\":{\"parameters\":[{\"name\":\"feature-engineering-query\",\"value\":\"{{inputs.parameters.feature-engineering-query}}\"},{\"name\":\"features-dataset-id\",\"value\":\"{{inputs.parameters.features-dataset-id}}\"},{\"name\":\"features-dataset-location\",\"value\":\"{{inputs.parameters.features-dataset-location}}\"},{\"name\":\"features-table-id\",\"value\":\"{{inputs.parameters.features-table-id}}\"},{\"name\":\"project-id\",\"value\":\"{{inputs.parameters.project-id}}\"}]}}]}}],\"entrypoint\":\"clv-training\",\"arguments\":{\"parameters\":[{\"name\":\"project-id\",\"value\":\"jk-caip\"},{\"name\":\"feature-engineering-query\",\"value\":\"\\\\nWITH\\\\n  '\n",
       "                                        'order_summaries as (\\\\n    '\n",
       "                                        'SELECT\\\\n      a.customer_id,\\\\n      '\n",
       "                                        'a.order_date,\\\\n      '\n",
       "                                        'a.order_value,\\\\n      '\n",
       "                                        'a.order_qty_articles\\\\n    FROM\\\\n    '\n",
       "                                        '(\\\\n      SELECT\\\\n        '\n",
       "                                        'customer_id,\\\\n        '\n",
       "                                        'order_date,\\\\n        '\n",
       "                                        'ROUND(SUM(unit_price * quantity), 2) '\n",
       "                                        'AS order_value,\\\\n        '\n",
       "                                        'SUM(quantity) AS '\n",
       "                                        'order_qty_articles,\\\\n        '\n",
       "                                        '(\\\\n          SELECT\\\\n            '\n",
       "                                        'MAX(order_date)\\\\n          '\n",
       "                                        'FROM\\\\n            '\n",
       "                                        '`jk-caip.lab_301.transactions` '\n",
       "                                        'tl\\\\n          WHERE\\\\n            '\n",
       "                                        'tl.customer_id = '\n",
       "                                        't.customer_id\\\\n        ) '\n",
       "                                        'latest_order\\\\n      FROM\\\\n        '\n",
       "                                        '`jk-caip.lab_301.transactions` '\n",
       "                                        't\\\\n      GROUP BY\\\\n          '\n",
       "                                        'customer_id,\\\\n          '\n",
       "                                        'order_date\\\\n    ) a\\\\n\\\\n    INNER '\n",
       "                                        'JOIN (\\\\n      -- Only customers with '\n",
       "                                        'more than one positive order values '\n",
       "                                        'before threshold.\\\\n      '\n",
       "                                        'SELECT\\\\n        customer_id\\\\n      '\n",
       "                                        'FROM (\\\\n        -- Customers and how '\n",
       "                                        'many positive order values  before '\n",
       "                                        'threshold.\\\\n        '\n",
       "                                        'SELECT\\\\n          '\n",
       "                                        'customer_id,\\\\n          '\n",
       "                                        'SUM(positive_value) '\n",
       "                                        'cnt_positive_value\\\\n        FROM '\n",
       "                                        '(\\\\n          -- Customer with '\n",
       "                                        'whether order was positive or not at '\n",
       "                                        'each date.\\\\n          '\n",
       "                                        'SELECT\\\\n            '\n",
       "                                        'customer_id,\\\\n            '\n",
       "                                        '(\\\\n              '\n",
       "                                        'CASE\\\\n                WHEN '\n",
       "                                        'SUM(unit_price * quantity) \\\\u003e 0 '\n",
       "                                        'THEN 1\\\\n                ELSE '\n",
       "                                        '0\\\\n              END ) '\n",
       "                                        'positive_value\\\\n          '\n",
       "                                        'FROM\\\\n            '\n",
       "                                        '`jk-caip.lab_301.transactions`\\\\n          '\n",
       "                                        'WHERE\\\\n            order_date '\n",
       "                                        '\\\\u003c '\n",
       "                                        'DATE(\\\\\"2011-08-08\\\\\")\\\\n          '\n",
       "                                        'GROUP BY\\\\n            '\n",
       "                                        'customer_id,\\\\n            '\n",
       "                                        'order_date)\\\\n        GROUP '\n",
       "                                        'BY\\\\n          customer_id )\\\\n      '\n",
       "                                        'WHERE\\\\n        cnt_positive_value '\n",
       "                                        '\\\\u003e 1\\\\n      ) b\\\\n    '\n",
       "                                        'ON\\\\n      a.customer_id = '\n",
       "                                        'b.customer_id\\\\n    --[START '\n",
       "                                        'common_clean]\\\\n    WHERE\\\\n      -- '\n",
       "                                        'Bought in the past 3 months\\\\n      '\n",
       "                                        'DATE_DIFF(DATE(\\\\\"2011-12-12\\\\\"), '\n",
       "                                        'latest_order, DAY) \\\\u003c= '\n",
       "                                        '90\\\\n      -- Make sure returns are '\n",
       "                                        'consistent.\\\\n      AND (\\\\n        '\n",
       "                                        '(order_qty_articles \\\\u003e 0 and '\n",
       "                                        'order_Value \\\\u003e 0) OR\\\\n        '\n",
       "                                        '(order_qty_articles \\\\u003c 0 and '\n",
       "                                        'order_Value \\\\u003c 0)\\\\n      '\n",
       "                                        '))\\\\n          \\\\nSELECT\\\\n  '\n",
       "                                        'tf.customer_id,\\\\n  -- For training '\n",
       "                                        'period\\\\n  -- Copying the '\n",
       "                                        'calculations from Lifetimes where '\n",
       "                                        'first orders are ignored\\\\n  -- See '\n",
       "                                        'https://github.com/CamDavidsonPilon/lifetimes/blob/master/lifetimes/utils.py#L246\\\\n--[START '\n",
       "                                        'features_target]\\\\n  '\n",
       "                                        'ROUND(tf.monetary, 2) as '\n",
       "                                        'monetary,\\\\n  tf.cnt_orders AS '\n",
       "                                        'frequency,\\\\n  tf.recency,\\\\n  '\n",
       "                                        'tf.T,\\\\n  '\n",
       "                                        'ROUND(tf.recency/cnt_orders, 2) AS '\n",
       "                                        'time_between,\\\\n  '\n",
       "                                        'ROUND(tf.avg_basket_value, 2) AS '\n",
       "                                        'avg_basket_value,\\\\n  '\n",
       "                                        'ROUND(tf.avg_basket_size, 2) AS '\n",
       "                                        'avg_basket_size,\\\\n  '\n",
       "                                        'tf.cnt_returns,\\\\n  -- Target '\n",
       "                                        'calculated for overall period\\\\n  '\n",
       "                                        'ROUND(tt.target_monetary, 2) as '\n",
       "                                        'target_monetary\\\\n--[END '\n",
       "                                        'features_target]\\\\nFROM\\\\n  -- This '\n",
       "                                        'SELECT uses only data before '\n",
       "                                        'threshold to make features.\\\\n  '\n",
       "                                        '(\\\\n    SELECT\\\\n      '\n",
       "                                        'customer_id,\\\\n      SUM(order_value) '\n",
       "                                        'AS monetary,\\\\n      '\n",
       "                                        'DATE_DIFF(MAX(order_date), '\n",
       "                                        'MIN(order_date), DAY) AS '\n",
       "                                        'recency,\\\\n      '\n",
       "                                        \"DATE_DIFF(DATE('2011-08-08'), \"\n",
       "                                        'MIN(order_date), DAY) AS T,\\\\n      '\n",
       "                                        'COUNT(DISTINCT order_date) AS '\n",
       "                                        'cnt_orders,\\\\n      '\n",
       "                                        'AVG(order_qty_articles) '\n",
       "                                        'avg_basket_size,\\\\n      '\n",
       "                                        'AVG(order_value) '\n",
       "                                        'avg_basket_value,\\\\n      '\n",
       "                                        'SUM(CASE\\\\n          WHEN order_value '\n",
       "                                        '\\\\u003c 1 THEN 1\\\\n          ELSE 0 '\n",
       "                                        'END) AS cnt_returns\\\\n    '\n",
       "                                        'FROM\\\\n      order_summaries a\\\\n    '\n",
       "                                        'WHERE\\\\n      order_date \\\\u003c= '\n",
       "                                        \"DATE('2011-08-08')\\\\n    GROUP \"\n",
       "                                        'BY\\\\n      customer_id) tf,\\\\n\\\\n  -- '\n",
       "                                        'This SELECT uses data after threshold '\n",
       "                                        'to calculate the target )\\\\n  (\\\\n    '\n",
       "                                        'SELECT\\\\n      customer_id,\\\\n      '\n",
       "                                        'SUM(order_value) '\n",
       "                                        'target_monetary\\\\n    FROM\\\\n      '\n",
       "                                        'order_summaries\\\\n      WHERE '\n",
       "                                        'order_date \\\\u003e '\n",
       "                                        \"DATE('2011-08-08')\\\\n    GROUP \"\n",
       "                                        'BY\\\\n      customer_id) '\n",
       "                                        'tt\\\\nWHERE\\\\n  tf.customer_id = '\n",
       "                                        'tt.customer_id\\\\n  AND tf.monetary '\n",
       "                                        '\\\\u003e 0\\\\n  AND tf.monetary '\n",
       "                                        '\\\\u003c= '\n",
       "                                        '15000\"},{\"name\":\"aml-compute-region\",\"value\":\"us-central1\"},{\"name\":\"features-table-id\",\"value\":\"features\"},{\"name\":\"features-dataset-id\",\"value\":\"lab_301\"},{\"name\":\"features-dataset-location\",\"value\":\"US\"},{\"name\":\"aml-dataset-name\",\"value\":\"clv_features\"},{\"name\":\"target-column-name\",\"value\":\"target_monetary\"},{\"name\":\"aml-model-name\",\"value\":\"clv_regression\"},{\"name\":\"train-budget\",\"value\":\"1000\"},{\"name\":\"primary-metric\",\"value\":\"mean_absolute_error\"},{\"name\":\"deployment-threshold\",\"value\":\"900\"}]},\"serviceAccountName\":\"pipeline-runner\"},\"status\":{\"startedAt\":null,\"finishedAt\":null}}'},\n",
       " 'resource_references': [{'key': {'id': '3fa9384c-b36c-46b5-8e96-64fdd549c1fe',\n",
       "                                  'type': 'EXPERIMENT'},\n",
       "                          'relationship': 'OWNER'}],\n",
       " 'scheduled_at': datetime.datetime(1970, 1, 1, 0, 0, tzinfo=tzlocal()),\n",
       " 'status': None,\n",
       " 'storage_state': None}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_experiment_name = 'CLV Training'\n",
    "_run_name = 'Run 01'\n",
    "_params = dict()\n",
    "\n",
    "try:\n",
    "    _experiment_ref = _client.get_experiment(_experiment_name)\n",
    "except:\n",
    "    _experiment_ref = _client.create_experiment(_experiment_name)\n",
    "\n",
    "_client.run_pipeline(\n",
    "    _experiment_ref.id,\n",
    "    _run_name,\n",
    "    pipeline_package_path=None,\n",
    "    params=_params,\n",
    "    pipeline_id = _pipeline_ref.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bq --project_id=$PROJECT_ID rm -r -f -d $DATASET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfx",
   "language": "python",
   "name": "tfx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
